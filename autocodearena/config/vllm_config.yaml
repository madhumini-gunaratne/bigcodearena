phi-2-vllm:
  api_type: vllm_local
  model: microsoft/phi-2
  endpoint: http://localhost:8000
  max_tokens: 512
  temperature: 0.7

qwen-vllm:
  api_type: vllm_local
  model: Qwen/Qwen2.5-7B-Instruct
  endpoint: http://localhost:8000
  max_tokens: 512
  temperature: 0.7

deepseek-vllm:
  api_type: vllm_local
  model: deepseek-ai/deepseek-coder-7b-instruct-v1.5
  endpoint: http://localhost:8000
  max_tokens: 512
  temperature: 0.7
